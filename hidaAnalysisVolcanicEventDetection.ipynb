{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding signatures of Volcanic Activity using global temperature changes\n",
    "=========\n",
    "\n",
    "_This notebook was developed following the [HIDA Datathlon Virtual Challenge](https://www.eventbrite.de/e/hida-datathon-virtual-challenge-registration-100891958564), held on April 2-3, 2020. The following was developed mostly in the days following that challenge._\n",
    "\n",
    "Given a set of global temperature data over 1000 years, and volcanic activity data, can we develop tools to accurately identify periods of high volcanic activity using only the temperature information?\n",
    "\n",
    "With this data, I am taking the opportunity to explore **time series data** a bit. As a particle physicist, we rarely work with time series data, so this is a good opportunity to learn some things about time series data manipulation.\n",
    "\n",
    "The first thing we need to do is to set up the data, below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "from scipy import signal\n",
    "\n",
    "# Helper functions used in other parts of the code\n",
    "import HelperModules\n",
    "import EngineeredFeatures\n",
    "\n",
    "ds = xr.open_dataset('MyChallengePaleo/T2m_R1_ym_1stMill.nc')\n",
    "T2m_R1 = ds.to_dataframe()\n",
    "\n",
    "TSI = HelperModules.getForcingData('MyChallengePaleo/Solar_forcing_1st_mill.nc','TSI')\n",
    "AOD = HelperModules.getForcingData('MyChallengePaleo/Volc_Forc_AOD_1st_mill.nc','AOD')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Data\n",
    "===============\n",
    "\n",
    "The temperature is influenced by *forcings*, so-called because they force the global temperature out of equilibrium, consisting of **solar** and **volcanic** forcing. Volcanic activity is indicated by the aerosol optical depth:\n",
    ">High values indicate a high sulfate load in the stratosphere, leading to a reflection and absorption of incoming short wave radiation in the stratosphere with the net-effectof a decrease in global mean temperatures.\n",
    "\n",
    "Solar forcing is measured in units of solar irradiance (Wm$^{-2}$). It has an 11-year cycle, plus more irregular, non-periodic variations. In the plot below, the long-term variation is highlighted by the red line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(15, 5))\n",
    "\n",
    "# Solar forcing\n",
    "color = 'gray'\n",
    "p1 = ax1.plot(TSI['time_yr'],TSI['TSI'],label='solar irradiance',color=color)\n",
    "ax1.set_xlabel('time (year)')\n",
    "ax1.set_ylabel('Solar irradiance [Wm$^{-2}$]',color=color)\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "ax1.set_xlim(-10,1010)\n",
    "ax1.set_ylim(1364,1366.5)\n",
    "\n",
    "# Rolling-average solar forcing\n",
    "p2 = ax1.plot(TSI['time_yr'],TSI['TSI'].rolling(window=11,center=True).mean(),label='solar irradiance (11-yr mean)',color='tab:red')\n",
    "\n",
    "# Volcanic forcing\n",
    "color = 'tab:blue'\n",
    "ax2 = ax1.twinx()\n",
    "p3 = ax2.plot(AOD['time_yr'],AOD['AOD'],label='volcanic AOD',color=color)\n",
    "ax2.set_ylabel('Aerosol Optical Depth',color=color)\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "ax2.set_ylim(-0.01,0.7);\n",
    "\n",
    "labs = [l.get_label() for l in p1+p2+p3]\n",
    "ax1.legend(p1+p2+p3, labs, loc=1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Temperature Data\n",
    "-----------\n",
    "Now let's look at the global temperature data. This dataset is constructed by running a 1000-year simulation of global temperatures, giving the solar and volcanic forcings above as an input. It consists of a temperature data point for every longitude and latitude, for each year of the entire 1000-year duration.\n",
    "\n",
    "Let's plot the **global average temperature** alongside the volcanic and the (long-term) solar activity for comparison:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 5))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "spacial_averaged = T2m_R1.groupby('time').mean()\n",
    "p1 = ax.plot(AOD['time_yr'],AOD['AOD'],label='volcanic AOD',color='gray')\n",
    "p2 = ax.plot(TSI['time_yr'],0.3*(-1363.0+TSI['TSI'].rolling(window=11,center=True).mean()),label='solar irradiance (11-yr mean), arb. units',color='red')\n",
    "ax.set_ylabel('Aerosol Optical Depth',color='gray')\n",
    "ax.set_ylim(0,0.9)\n",
    "\n",
    "ax2 = ax.twinx()\n",
    "p3 = ax2.plot(np.round(spacial_averaged.index/10000),list(spacial_averaged.values),label='Average global temperature')\n",
    "ax2.set_ylabel('Average global temperature',color='tab:blue')\n",
    "ax2.tick_params(axis='y', labelcolor='tab:blue')\n",
    "ax2.set_ylim(274.5,278.3)\n",
    "\n",
    "labs = [l.get_label() for l in p1+p2+p3]\n",
    "ax.legend(p1+p2+p3, labs, loc=3)\n",
    "\n",
    "plt.xlabel('time [years]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting Autocorrelation and Power Spectra of the Temperature Data\n",
    "==========\n",
    "A time series is **_stationary_** if the current value is not based in any way on the previous value (e.g. a random walk). From \"Forecasting: Principles and Practice\":\n",
    "> In general, a stationary time series will have no predictable patterns in the long-term. Time plots will show the series to be roughly horizontal (although some cyclic behaviour is possible), with constant variance.\n",
    "\n",
    "Some of the typical tools for determining the nature of time series data include *autocorrelation*, the correlation of the data with a time-delay of itself. If a time series is not random but has an underlying structure, for instance a periodic signal, then an autocorrelation plot might shed light on this behavior. Here is what that looks like for this dataset, below.\n",
    "\n",
    "From these plots, it is clear that (a) the temperature is clearly correlated with the years immediately preceding, but (b) otherwise there is no discernable pattern in the data -- not even the 11-year solar cycle is visible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temporal_averaged = EngineeredFeatures.getGlobalTemperatureAverageSeries(T2m_R1['T2m'])\n",
    "ta_diff = temporal_averaged.diff().fillna(0)\n",
    "fig = plt.figure(figsize=(15, 4))\n",
    "ax1 = fig.add_subplot(1, 2, 1,label='ax1')\n",
    "pd.plotting.autocorrelation_plot(temporal_averaged,ax=ax1,label='autocorrelation of data')\n",
    "ax2 = fig.add_subplot(1, 2, 2)\n",
    "pd.plotting.autocorrelation_plot(ta_diff,ax=ax2,label='autocorrelation of differenced data');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Periodogram (Power Spectrum)\n",
    "-----------\n",
    "\n",
    "Similarly, a periodogram (or power spectrum) of the data shows no discernable maxima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 4))\n",
    "frequencies, power_spectrum = signal.periodogram(temporal_averaged,30)\n",
    "ax = plt.semilogy(frequencies, power_spectrum)\n",
    "plt.ylabel('Spectrum')\n",
    "plt.xlabel('Frequency [year]');\n",
    "#plt.xlim(8,15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Differencing the Temperature Data as a way to find volcanic activity\n",
    "=========\n",
    "Another way to visualize time series is by *differencing*, e.g. plotting the change in values for each series step. If a series is not _stationary_, then it is possible that the differenced version of the time series is stationary (e.g. a random walk). Differencing is investigated for this dataset below.\n",
    "\n",
    "Since we know that volcanic activity causes a drop in the temperature, we should look for that. But we don't want to just set a temperature thresold; then low solar activity, or simply a statistical fluctuation, could trigger a false volcanic \"alarm\". So we use the year-over-year temperature **_difference_** to find large, sudden changes in the temperature. This will work both in relatively cold periods as well as warm ones.\n",
    "\n",
    "In the end it took a bit of fiddling to find something that looked good (e.g. not too noisy), namely: a **5-year rolling average of temperatures, differenced, that difference itself averaged over 4 years.**\n",
    "\n",
    "The differencing, shown below, reveals large negative spikes that correlate closely with periods of large volcanic activity. Setting a simple threshold on this quantity is a good predictor of volcanic activity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temporal_averaged = EngineeredFeatures.getGlobalTemperatureAverageSeries(T2m_R1['T2m'])\n",
    "ta_diff = temporal_averaged.rolling(window=5).mean().diff().fillna(0).rolling(window=4).mean()\n",
    "\n",
    "def indexToYear(index) :\n",
    "    return np.round(index/10000)\n",
    "\n",
    "fig = plt.figure(figsize=(15, 5))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "AOD['volcanicDeltaFunc'] = ((AOD['AOD'].diff() > 0.01) &\n",
    "                            (AOD['AOD'].diff().shift(1) < 0.01) &\n",
    "                            (AOD['AOD'].diff().shift(2) < 0.01) &\n",
    "                            (AOD['AOD'].diff().shift(3) < 0.01) &\n",
    "                            (AOD['AOD'].diff().shift(4) < 0.01) &\n",
    "                            (AOD['AOD'].diff().shift(5) < 0.01)\n",
    "                           )\n",
    "\n",
    "ax.plot(indexToYear(ta_diff.index),ta_diff.values)\n",
    "ax.plot(AOD['time_yr'],AOD['AOD'],label='volcanic AOD',color='red')\n",
    "ax.plot(AOD['time_yr'],-0.35+0.05*AOD['volcanicDeltaFunc'],label='volcanic AOD',color='orange')\n",
    "ax.plot(indexToYear(ta_diff.index),-0.45+0.05*(ta_diff < -0.06),label='volcanic AOD',color='purple')\n",
    "\n",
    "plt.xlabel('time [years]')\n",
    "plt.ylabel('diff(temperature) OR volcanic activity')\n",
    "\n",
    "plt.text(5,0.1,'Volcanic activity',color='red')\n",
    "plt.text(5,-0.1,'global diff(Temperature)',color='tab:blue')\n",
    "plt.text(5,-0.33,'True events',color='orange')\n",
    "plt.text(5,-0.43,'Events passing threshold',color='purple')\n",
    "plt.text(775,-0.43,'FP',color='purple')\n",
    "ax.set_xlim(0,1000);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This simple differencing technique found all eight \"major events\", two \"minor events\" (out of 14), and had one false positive - not bad for a couple of simple transformations! Let's see if we can improve a bit by picking out a subset of the data, namely the temperate and tropical zones.\n",
    "\n",
    "In the end, this one does not do much better, but it might give you a little bit more information about the location (southern or northern hemisphere) of the volcanic activity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_hemi = HelperModules.getLatSlice(T2m_R1,-61,0)\n",
    "s_hemi_avg = EngineeredFeatures.getGlobalTemperatureAverageSeries(s_hemi['T2m'])\n",
    "ta_diff_s = s_hemi_avg.rolling(window=5).mean().diff().fillna(0).rolling(window=4).mean()\n",
    "\n",
    "n_hemi = HelperModules.getLatSlice(T2m_R1,0,61)\n",
    "n_hemi_avg = EngineeredFeatures.getGlobalTemperatureAverageSeries(n_hemi['T2m'])\n",
    "ta_diff_n = n_hemi_avg.rolling(window=5).mean().diff().fillna(0).rolling(window=4).mean()\n",
    "\n",
    "fig = plt.figure(figsize=(15, 5))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.plot(indexToYear(ta_diff_s.index),ta_diff_s.values,color='tab:blue')\n",
    "ax.plot(indexToYear(ta_diff_n.index),ta_diff_n.values,color='lightblue')\n",
    "\n",
    "ax.plot(AOD['time_yr'],AOD['AOD'],label='volcanic AOD',color='red')\n",
    "ax.plot(AOD['time_yr'],-0.35+0.05*AOD['volcanicDeltaFunc'],label='volcanic AOD',color='orange')\n",
    "so_or_north = -0.45+0.05*(((ta_diff_s < -0.070) & (ta_diff_n < -0.020)) |\n",
    "                          ((ta_diff_n < -0.070) & (ta_diff_s < -0.020)) |\n",
    "                          (ta_diff_s + ta_diff_n < -0.10))\n",
    "ax.plot(indexToYear(ta_diff_s.index),so_or_north,label='volcanic AOD',color='purple')\n",
    "\n",
    "plt.text(5,0.1,'Volcanic activity',color='red')\n",
    "plt.text(5,-0.1,'Southern hemisphere',color='tab:blue')\n",
    "plt.text(5,-0.15,'Northern hemisphere',color='lightblue')\n",
    "plt.text(5,-0.33,'True events',color='orange')\n",
    "plt.text(5,-0.43,'Events passing threshold',color='purple')\n",
    "plt.text(965,-0.43,'FP',color='purple')\n",
    "\n",
    "plt.xlabel('time [years]')\n",
    "plt.ylabel('diff(temperature) OR volcanic activity')\n",
    "ax.set_xlim(0,1000);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Machine Learning to boost the signal\n",
    "==========\n",
    "\n",
    "We seem to have gotten as far as we could by just playing with the data, so now we have two options: we could spend a lot more time to try to understand the data, tinkering and finding more features, or we could throw things into Machine Learning and see if it can beat us. The latter will be faster, albeit with maybe fewer insights. But since part of the goal is to get more experience with Machine Learning, let's try this approach.\n",
    "\n",
    "Setting up the training data\n",
    "------\n",
    "\n",
    "First, we split the data into windows, each with 18 years, and then label them as true volcano events or false ones. To slightly boost our statistics, we consider a year to host a true volcano event if it's within 1 year of the start of the volcanic activity.\n",
    "\n",
    "Our background dataset consists of any data window, provided it has 18 years in the window and the beginning is at least 8 years away from the start of a volcanic event. This provides us with plenty of background events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 5))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "window_yr = 18\n",
    "\n",
    "volcano_years = AOD[AOD['volcanicDeltaFunc'] == True]['time_yr'][:-1]\n",
    "years_volcano_true = np.asarray(volcano_years.values.tolist() +\n",
    "                                (volcano_years.values + 1).tolist() +\n",
    "                                (volcano_years.values - 1).tolist()\n",
    "                               )*10000+716.0\n",
    "\n",
    "non_volcano = (AOD['volcanicDeltaFunc'] == False)\n",
    "for i in range(8) :\n",
    "    non_volcano = (non_volcano & (AOD['volcanicDeltaFunc'].shift(-i) == False))\n",
    "for i in range(8) :\n",
    "    non_volcano = (non_volcano & (AOD['volcanicDeltaFunc'].shift(i) == False))\n",
    "\n",
    "non_volcano_years = AOD[non_volcano]['time_yr'][:-19]\n",
    "years_volcano_false = non_volcano_years.values*10000+716.0\n",
    "\n",
    "all_years = AOD['time_yr'][:-19]\n",
    "years_all_t2m = all_years.values*10000+716.0\n",
    "\n",
    "x_sig,x_sig_yr = [],[]\n",
    "x_bkg,x_bkg_yr = [],[]\n",
    "x_all,x_all_yr = [],[]\n",
    "\n",
    "ax.plot(AOD['time_yr'],AOD['AOD'],label='volcanic AOD',color='red')\n",
    "\n",
    "for i in years_volcano_true :\n",
    "    ta_diff_subset = ta_diff[i:i+window_yr*10000]\n",
    "    year = np.round(i/10000)\n",
    "    ax.plot(indexToYear(ta_diff_subset.index),ta_diff_subset.values)\n",
    "    x_sig.append(ta_diff_subset.values.tolist())\n",
    "    x_sig_yr.append(year)\n",
    "\n",
    "for i in non_volcano_years.values*10000+716.0 :\n",
    "    year = np.round(i/10000)\n",
    "    ta_diff_subset = ta_diff[i:i+window_yr*10000]\n",
    "    x_bkg.append(ta_diff_subset.values.tolist())\n",
    "    x_bkg_yr.append(year)\n",
    "\n",
    "for i in years_all_t2m :\n",
    "    year = np.round(i/10000)\n",
    "    ta_diff_subset = ta_diff[i:i+window_yr*10000]\n",
    "    x_all.append(ta_diff_subset.values.tolist())\n",
    "    x_all_yr.append(year)\n",
    "    \n",
    "plt.xlabel('time [years]')\n",
    "plt.ylabel('diff(temperature) OR volcanic activity')\n",
    "\n",
    "plt.text(5,0.1,'Volcanic activity',color='red')\n",
    "plt.text(5,0.15,'signal events (colored)',color='black')\n",
    "ax.set_xlim(0,1000)\n",
    "\n",
    "x_sig = np.array(list(a for a in x_sig))\n",
    "print(\"Shape of signal events:\",x_sig.shape)\n",
    "\n",
    "x_bkg = np.array(list(a for a in x_bkg))\n",
    "print(\"Shape of bkg events:\",x_bkg.shape)\n",
    "\n",
    "x_all = np.array(list(a for a in x_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train = np.append(x_sig,x_bkg,axis=0)\n",
    "all_train_labels = np.append([True]*x_sig.shape[0],[False]*x_bkg.shape[0])\n",
    "all_train_years = np.append(x_sig_yr,x_bkg_yr)\n",
    "\n",
    "df_train = pd.DataFrame(all_train_labels,columns=['label'])\n",
    "df_train['year'] = all_train_years\n",
    "\n",
    "df_test = pd.DataFrame(x_all_yr,columns=['year'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model\n",
    "----------\n",
    "\n",
    "As a model, let's use keras, via tensorflow, and pick a neural network with two hidden layers, each with 5 nodes. We finish with a sigmoid function layer for a binary output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print('Tensorflow version:',tf.__version__)\n",
    "\n",
    "np.random.seed(1)\n",
    "tf.random.set_seed(1)\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "#   tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(5, name='first_dense', input_shape=(19,), activation='relu'),\n",
    "    tf.keras.layers.Dense(5, name='middle_dense', activation='relu'),\n",
    "#   tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(1, name='last_dense', activation='sigmoid') # sigmoid for binary; softmax for multi?\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    all_train,\n",
    "    all_train_labels,\n",
    "    batch_size=64,\n",
    "    epochs=20,\n",
    "    verbose=0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating the Model\n",
    "-------\n",
    "Taking a look at the confusion matrix below, it seems like our model has done a terrible job. However, if we plot the discriminant itself, there seems to be plenty of discriminating power. We can set a discriminating value by hand to select the signal acceptance / false positive rate that we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "df_train['binary_prediction'] = model.predict_classes(all_train)\n",
    "confusion_matrix(df_train['binary_prediction'],all_train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['discriminant'] = model.predict(all_train)\n",
    "df_test['discriminant'] = model.predict(x_all)\n",
    "rng=[0.15,0.47]\n",
    "\n",
    "plt.hist(df_train['discriminant'],bins=40,label='all',density=False,histtype='stepfilled',lw=2,range=rng,color='lightblue')\n",
    "plt.hist(df_train[df_train['label'] ==1]['discriminant'],bins=40,label='sig',density=False,histtype='step',lw=2,range=rng)\n",
    "plt.hist(df_train[df_train['label'] ==0]['discriminant'],bins=40,label='bkg',density=False,histtype='step',lw=2,range=rng)\n",
    "\n",
    "plt.legend()\n",
    "plt.yscale('log')\n",
    "plt.xlabel('discriminant value')\n",
    "plt.ylabel('events');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's plot our chosen signal events and compare them to our naive threshold method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 5))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "ax.plot(indexToYear(ta_diff.index),ta_diff.values)\n",
    "ax.plot(AOD['time_yr'],AOD['AOD'],label='volcanic AOD',color='red')\n",
    "ax.plot(AOD['time_yr'],-0.35+0.05*AOD['volcanicDeltaFunc'],label='volcanic AOD',color='orange')\n",
    "ax.plot(indexToYear(ta_diff.index),-0.45+0.05*(ta_diff < -0.06),label='volcanic AOD',color='purple')\n",
    "ax.plot(df_test['year'],-0.55+0.05*(df_test['discriminant'] > 0.334),color='green')\n",
    "\n",
    "plt.text(5,0.1,'Volcanic activity',color='red')\n",
    "plt.text(5,-0.1,'global diff(Temperature)',color='tab:blue')\n",
    "plt.text(5,-0.33,'True events',color='orange')\n",
    "plt.text(5,-0.43,'Events passing threshold',color='purple')\n",
    "plt.text(5,-0.53,'Keras NN',color='green')\n",
    "plt.text(775,-0.43,'FP',color='purple')\n",
    "plt.text(772,-0.53,'FP',color='green')\n",
    "\n",
    "plt.xlabel('time [years]')\n",
    "plt.ylabel('diff(temperature) OR volcanic activity')\n",
    "ax.set_xlim(0,1000);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay - the simple neural network did pretty well! It managed to get all 8 major events, plus 4 minor events, with only 1 false positive. You'll remember that the naive threshold-setting method (\"Events passing threshold\") caught only 2 minor events, also with one false positive. Even with 0 tweaking, the neural net seems to do quite well.\n",
    "\n",
    "Wrapping Up, for now\n",
    "-----------\n",
    "We could continue to tweak this NN -- perhaps giving it more fine-grained information on temperatures in different regions, or using a more targeted ML approach such as **Long short-term memory networks (LSTM)**. However, to do this properly we would probably need a larger dataset, to avoid things like overtraining. Thus, I think the main takeaway of this exercise is this: that a naive approach gets you pretty far in terms of signal detection, and machine learning can take you a bit farther... however at the cost of obscuring the mechanism that bring such success."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
